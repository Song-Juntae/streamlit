import streamlit as st
import streamlit.components.v1 as components

import plotly.express as px
import plotly.graph_objects as go

from collections import Counter

from PIL import Image

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import koreanize_matplotlib

from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer

from wordcloud import WordCloud
########################################################################################################################
def get_count_top_words(df, start_date=None, last_date=None, num_words=10, name=None, sentiment = None, item = None, source = None ):
    if name is not None:
        df = df[df['name'] == name]
    if sentiment is not None:
        df = df[df['sentiment'] == sentiment]
    if item is not None:
        df = df[df['item'] == item]
    if source is not None:
        df = df[df['source'] == source]
    if start_date is None:
        start_date = df['time'].min().strftime('%Y-%m-%d')
    if last_date is None:
        last_date = df['time'].max().strftime('%Y-%m-%d')
    df = df[(df['time'] >= start_date) & (df['time'] <= last_date)]
    count_vectorizer = CountVectorizer()
    count = count_vectorizer.fit_transform(df['noun'].values)
    count_df = pd.DataFrame(count.todense(), columns=count_vectorizer.get_feature_names_out())
    count_top_words = count_df.sum().sort_values(ascending=False).head(num_words).to_dict()
    return count_top_words
########################################################################################################################
# ë°ì´í„° ë¡œë“œ
df_ë¦¬ë·°_ê°ì„±ë¶„ì„ê²°ê³¼ = pd.read_csv('/app/streamlit/data/ë¦¬ë·°6ì°¨.csv')
df_ë¦¬ë·°_ê°ì„±ë¶„ì„ê²°ê³¼['time'] = pd.to_datetime(df_ë¦¬ë·°_ê°ì„±ë¶„ì„ê²°ê³¼['time'])

words = get_count_top_words(df_ë¦¬ë·°_ê°ì„±ë¶„ì„ê²°ê³¼)
########################################################################################################################
# ë ˆì´ì•„ì›ƒ
# with st.container():
#     col1, col2, col3 = st.columns([1,1,1])
# with st.container():
#     col4, col5, col6 = st.columns([1,1,1])

tab1, tab2, tab3 = st.tabs(["All", "PositiveğŸ˜Š", "NegativeğŸ˜«"])

with tab1:
    st.header("ëª¨ë“  ë¦¬ë·°")


with st.expander('=== ê¸°ì—…ì„ íƒí•˜ê¸° ==='):

    st.write(df_ë¦¬ë·°_ê°ì„±ë¶„ì„ê²°ê³¼['name'].unique())







########################################################################################################################
# íŒŒì´ì°¨íŠ¸
with col1:
    df_íŒŒì´ì°¨íŠ¸ = pd.DataFrame(df_ë¦¬ë·°_ê°ì„±ë¶„ì„ê²°ê³¼['sentiment'].value_counts())
    pie_chart = go.Figure(data=[go.Pie(labels=list(df_íŒŒì´ì°¨íŠ¸.index), values=df_íŒŒì´ì°¨íŠ¸['count'])])
    st.plotly_chart(pie_chart, use_container_width=True)
########################################################################################################################
# ì›Œë“œí´ë¼ìš°ë“œ
with col2:
    cand_mask = np.array(Image.open('/app/streamlit/data/circle.png'))
    ì›Œë“œí´ë¼ìš°ë“œ = WordCloud(
        background_color="white", 
        max_words=1000,
        font_path = "/app/streamlit/font/NanumBarunGothic.ttf", 
        contour_width=3, 
        colormap='Spectral', 
        contour_color='white',
        mask=cand_mask).generate_from_frequencies(words)
    fig, ax = plt.subplots()
    ax.imshow(ì›Œë“œí´ë¼ìš°ë“œ, interpolation='bilinear')
    st.pyplot(fig, use_container_width=True)
########################################################################################################################
# ë°”ì°¨íŠ¸
with col3:
    st.bar_chart(words)
########################################################################################################################
# ë°”ì°¨íŠ¸
with col5:
    st.bar_chart(words)
########################################################################################################################
# ë„¤íŠ¸ì›Œí¬ ì°¨íŠ¸
from gensim.models import Word2Vec
import networkx as nx
from pyvis.network import Network

st.title('í‚¤ì›Œë“œ ë„¤íŠ¸ì›Œí¬ íŒŒì•…')
keywords = st.text_imput('í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”', value='ì œë¼ëŠ„')


keywords = ['ë¿Œë¦¬','ì œë¼ëŠ„', 'ì‹ë¬¼', 'ì‘ì• ']

reviews = [eval(i) for i in df_ë¦¬ë·°_ê°ì„±ë¶„ì„ê²°ê³¼['noun']]

networks = []
for review in reviews:
    network_review = [w for w in review if len(w) > 1]
    networks.append(network_review)

model = Word2Vec(networks, vector_size=100, window=5, min_count=1, workers=4, epochs=100)

G = nx.Graph(font_path='/app/streamlit/font/NanumBarunGothic.ttf')

# ì¤‘ì‹¬ ë…¸ë“œë“¤ì„ ë…¸ë“œë¡œ ì¶”ê°€
for keyword in keywords:
    G.add_node(keyword)
    # ì£¼ì–´ì§„ í‚¤ì›Œë“œì™€ ê°€ì¥ ìœ ì‚¬í•œ 20ê°œì˜ ë‹¨ì–´ ì¶”ì¶œ
    similar_words = model.wv.most_similar(keyword, topn=20)
    # ìœ ì‚¬í•œ ë‹¨ì–´ë“¤ì„ ë…¸ë“œë¡œ ì¶”ê°€í•˜ê³ , ì£¼ì–´ì§„ í‚¤ì›Œë“œì™€ì˜ ì—°ê²°ì„  ì¶”ê°€
    for word, score in similar_words:
        G.add_node(word)
        G.add_edge(keyword, word, weight=score)
        
# ë…¸ë“œ í¬ê¸° ê²°ì •
size_dict = nx.degree_centrality(G)

# ë…¸ë“œ í¬ê¸° ì„¤ì •
node_size = []
for node in G.nodes():
    if node in keywords:
        node_size.append(5000)
    else:
        node_size.append(1000)

# í´ëŸ¬ìŠ¤í„°ë§
clusters = list(nx.algorithms.community.greedy_modularity_communities(G))
cluster_labels = {}
for i, cluster in enumerate(clusters):
    for node in cluster:
        cluster_labels[node] = i
        
# ë…¸ë“œ ìƒ‰ìƒ ê²°ì •
color_palette = ["#f39c9c", "#f7b977", "#fff4c4", "#d8f4b9", "#9ed6b5", "#9ce8f4", "#a1a4f4", "#e4b8f9", "#f4a2e6", "#c2c2c2"]
node_colors = [color_palette[cluster_labels[node] % len(color_palette)] for node in G.nodes()]

# ë…¸ë“œì— ë¼ë²¨ê³¼ ì—°ê²° ê°•ë„ ê°’ ì¶”ê°€
edge_weights = [d['weight'] for u, v, d in G.edges(data=True)]

# ì„ ì˜ ê¸¸ì´ë¥¼ ë³€ê²½ pos
plt.figure(figsize=(15,15))
pos = nx.spring_layout(G, seed=42, k=0.15)
nx.draw(G, pos, font_family='NanumGothic', with_labels=True, node_size=node_size, node_color=node_colors, alpha=0.8, linewidths=1,
        font_size=9, font_color="black", font_weight="medium", edge_color="grey", width=edge_weights)


# ì¤‘ì‹¬ ë…¸ë“œë“¤ë¼ë¦¬ ê²¹ì¹˜ëŠ” ë‹¨ì–´ ì¶œë ¥
overlapping_keywords = set()
for i, keyword1 in enumerate(keywords):
    for j, keyword2 in enumerate(keywords):
        if i < j and keyword1 in G and keyword2 in G:
            if nx.has_path(G, keyword1, keyword2):
                overlapping_keywords.add(keyword1)
                overlapping_keywords.add(keyword2)
if overlapping_keywords:
    print(f"ë‹¤ìŒ ì¤‘ì‹¬ í‚¤ì›Œë“œë“¤ë¼ë¦¬ ì—°ê´€ì„±ì´ ìˆì–´ ì¤‘ë³µë  ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤: {', '.join(overlapping_keywords)}")


net = Network(notebook=True, cdn_resources='in_line')

net.from_nx(G)

net.save_graph(f'/app/streamlit/pyvis_graph.html')
HtmlFile = open(f'/app/streamlit/pyvis_graph.html', 'r', encoding='utf-8')
components.html(HtmlFile.read(), height=435)

st.success(f'<{}>')



########################################################################################################################
########################################################################################################################
########################################################################################################################
########################################################################################################################
########################################################################################################################
########################################################################################################################
